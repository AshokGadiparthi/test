---
# config.yaml (host on GCS, passed via --configGcsPath)
dataQuality:
  # Fields to join on
  joinKeys:
    - cust_id
    - acct_num
    - mtn
  comparison:
    columns:
      - name: status
        type: STRING
    ruleType: "equals"
stages:
  - name: orig
    type: BIGQUERY
    table: "PROJECT:DS.table1"
    jsonRoot: ""       # non‑JSON, fields at top level
  - name: gg_replica
    type: BIGQUERY
    table: "PROJECT:DS.gg_replica"
    jsonRoot: "/after" # JSON under "after"
  - name: payloads
    type: BIGQUERY
    table: "PROJECT:DS.payloads_table"
    jsonRoot: ""       # JSON fields at root
  - name: new
    type: BIGQUERY
    table: "PROJECT:DS.table2"
    jsonRoot: ""       # non‑JSON
outputs:
  audit:       "PROJECT:DS.compare_audit"
  rootCause:   "PROJECT:DS.compare_root_cause"
  parseErrors: "PROJECT:DS.data_quality_parse_errors"
---

// AppConfig.java
package com.trustiq.config;

import java.util.List;

public class AppConfig {
    private DataQualityConfig dataQuality;
    private List<StageConfig> stages;
    private Outputs outputs;

    public DataQualityConfig getDataQuality() { return dataQuality; }
    public void setDataQuality(DataQualityConfig dq) { this.dataQuality = dq; }

    public List<StageConfig> getStages() { return stages; }
    public void setStages(List<StageConfig> stages) { this.stages = stages; }

    public Outputs getOutputs() { return outputs; }
    public void setOutputs(Outputs outputs) { this.outputs = outputs; }

    public static class Outputs {
        private String audit;
        private String rootCause;
        private String parseErrors;

        public String getAudit() { return audit; }
        public void setAudit(String audit) { this.audit = audit; }

        public String getRootCause() { return rootCause; }
        public void setRootCause(String rootCause) { this.rootCause = rootCause; }

        public String getParseErrors() { return parseErrors; }
        public void setParseErrors(String parseErrors) { this.parseErrors = parseErrors; }
    }
}

// DataQualityConfig.java
package com.trustiq.config;

import java.util.List;

public class DataQualityConfig {
    private List<String> joinKeys;
    private ComparisonConfig comparison;

    public List<String> getJoinKeys() { return joinKeys; }
    public void setJoinKeys(List<String> joinKeys) { this.joinKeys = joinKeys; }

    public ComparisonConfig getComparison() { return comparison; }
    public void setComparison(ComparisonConfig comparison) { this.comparison = comparison; }
}

// ComparisonConfig.java
package com.trustiq.config;

import java.util.List;

public class ComparisonConfig {
    private List<ColumnConfig> columns;
    private String ruleType;

    public List<ColumnConfig> getColumns() { return columns; }
    public void setColumns(List<ColumnConfig> columns) { this.columns = columns; }

    public String getRuleType() { return ruleType; }
    public void setRuleType(String ruleType) { this.ruleType = ruleType; }
}

// ColumnConfig.java
package com.trustiq.config;

public class ColumnConfig {
    private String name;
    private String type;
    private Double tolerance;

    public String getName() { return name; }
    public void setName(String name) { this.name = name; }

    public String getType() { return type; }
    public void setType(String type) { this.type = type; }

    public Double getTolerance() { return tolerance; }
    public void setTolerance(Double tolerance) { this.tolerance = tolerance; }
}

// StageConfig.java
package com.trustiq.config;

public class StageConfig {
    private String name;
    private String type;
    private String table;
    private String jsonRoot;

    public String getName() { return name; }
    public void setName(String name) { this.name = name; }

    public String getType() { return type; }
    public void setType(String type) { this.type = type; }

    public String getTable() { return table; }
    public void setTable(String table) { this.table = table; }

    public String getJsonRoot() { return jsonRoot; }
    public void setJsonRoot(String jsonRoot) { this.jsonRoot = jsonRoot; }
}

---

// DataQualityPipeline.java
package com.trustiq.pipeline;

import com.fasterxml.jackson.databind.JsonNode;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.google.api.services.bigquery.model.*;
import com.google.cloud.bigquery.LegacySQLTypeName;
import com.trustiq.config.*;
import org.apache.beam.runners.dataflow.DataflowRunner;
import org.apache.beam.sdk.Pipeline;
import org.apache.beam.sdk.io.gcp.bigquery.BigQueryIO;
import org.apache.beam.sdk.options.*;
import org.apache.beam.sdk.transforms.*;
import org.apache.beam.sdk.transforms.join.CoGbkResult;
import org.apache.beam.sdk.transforms.join.KeyedPCollectionTuple;
import org.apache.beam.sdk.transforms.join.TupleTag;
import org.apache.beam.sdk.values.*;

import java.io.IOException;
import java.time.Instant;
import java.util.*;
import java.util.stream.Collectors;

public class DataQualityPipeline {

    public interface Options extends PipelineOptions, DataflowPipelineOptions {
        @Description("GCS URI to config.yaml")
        @Validation.Required String getConfigGcsPath();
        void setConfigGcsPath(String v);

        @Description("BQ table1: legacy CJCM")
        @Validation.Required String getTable1();
        void setTable1(String v);

        @Description("BQ table2: final Cassandra BQ")
        @Validation.Required String getTable2();
        void setTable2(String v);

        @Description("BQ gg_replica JSON source")
        @Validation.Required String getGgTable();
        void setGgTable(String v);

        @Description("BQ payloads_table JSON source")
        @Validation.Required String getPayloadTable();
        void setPayloadTable(String v);

        @Description("BQ output for audit counts")
        @Validation.Required String getAuditOutput();
        void setAuditOutput(String v);

        @Description("BQ output for root-cause details")
        @Validation.Required String getRootCauseOutput();
        void setRootCauseOutput(String v);

        @Description("BQ output for JSON parse errors")
        @Validation.Required String getErrorOutput();
        void setErrorOutput(String v);
    }

    public static void main(String[] args) {
        Options opts = PipelineOptionsFactory.fromArgs(args).withValidation().as(Options.class);
        opts.setRunner(DataflowRunner.class);

        AppConfig cfg = ConfigLoader.load(opts.getConfigGcsPath());
        DataQualityConfig dq = cfg.getDataQuality();
        List<String> joinKeys = dq.getJoinKeys();
        List<ColumnConfig> cols = dq.getComparison().getColumns();
        String rule = dq.getComparison().getRuleType();

        // Fetch schema types for table1
        com.google.cloud.bigquery.BigQuery bq =
          com.google.cloud.bigquery.BigQueryOptions.getDefaultInstance().getService();
        com.google.cloud.bigquery.TableId tid = parseTableId(opts.getTable1());
        com.google.cloud.bigquery.Schema schema = bq.getTable(tid).getDefinition().getSchema();
        List<KV<String,LegacySQLTypeName>> typeList = new ArrayList<>();
        for (com.google.cloud.bigquery.Field f : schema.getFields()) {
            typeList.add(KV.of(f.getName(), f.getType()));
        }

        Pipeline p = Pipeline.create(opts);
        PCollectionView<Map<String,LegacySQLTypeName>> typeView = p
          .apply("TypeList", Create.of(typeList))
          .apply("TypeMap", View.asMap());

        ObjectMapper mapper = new ObjectMapper();
        TupleTag<TableRow> errTag = new TupleTag<>("errors");

        // Extract JSON from DATA column
        class ExtractFn extends DoFn<TableRow, KV<String,TableRow>> {
            private final String stage;
            private final String jsonRoot;
            ExtractFn(String stage, String jsonRoot) {
                this.stage = stage;
                this.jsonRoot = jsonRoot;
            }
            @ProcessElement
            public void process(ProcessContext c) {
                TableRow row = c.element();
                try {
                    JsonNode root = mapper.readTree((String) row.get("DATA"));
                    JsonNode data = jsonRoot.isEmpty() ? root : root.at(jsonRoot);
                    String custId = data.path("cust_id").asText(null);
                    String acctNum = data.path("acct_num").asText(null);
                    String mtn = data.path("mtn").asText(null);
                    String key = String.join("|", custId, acctNum, mtn);

                    TableRow out = new TableRow()
                        .set("cust_id", custId)
                        .set("acct_num", acctNum)
                        .set("mtn", mtn);
                    for (ColumnConfig cc : cols) {
                        if (!joinKeys.contains(cc.getName())) {
                            out.set(cc.getName(), data.path(cc.getName()).asText(null));
                        }
                    }
                    c.output(KV.of(key, out));
                } catch (IOException e) {
                    c.output(errTag, new TableRow()
                        .set("stage", stage)
                        .set("raw_data", row.get("DATA"))
                        .set("error", e.getMessage())
                        .set("ts", Instant.now().toString()));
                }
            }
        }

        // Read & key Table1
        PCollection<KV<String,TableRow>> orig = p
          .apply("ReadT1", BigQueryIO.readTableRows().from(opts.getTable1()))
          .apply("KeyT1", MapElements.into(
            TypeDescriptors.kvs(TypeDescriptors.strings(), TypeDescriptor.of(TableRow.class)))
            .via(r -> KV.of(
              joinKeys.stream().map(k -> Objects.toString(r.get(k), "")).collect(Collectors.joining("|")), r)));

        // Read & parse gg_replica
        PCollectionTuple ggSplit = p.apply("ReadGG", BigQueryIO.readTableRows().from(opts.getGgTable()))
          .apply("ExtractGG", ParDo.of(new ExtractFn("gg_replica", "/after"))
            .withOutputTags(new TupleTag<KV<String,TableRow>>() {}, TupleTagList.of(errTag)));
        PCollection<KV<String,TableRow>> gg = ggSplit.get(new TupleTag<KV<String,TableRow>>(){});

        // Read & parse payloads_table
        PCollectionTuple plSplit = p.apply("ReadPL", BigQueryIO.readTableRows().from(opts.getPayloadTable()))
          .apply("ExtractPL", ParDo.of(new ExtractFn("payloads_table", ""))
            .withOutputTags(new TupleTag<KV<String,TableRow>>() {}, TupleTagList.of(errTag)));
        PCollection<KV<String,TableRow>> payload = plSplit.get(new TupleTag<KV<String,TableRow>>(){});

        // Read & key Table2
        PCollection<KV<String,TableRow>> fin = p
          .apply("ReadT2", BigQueryIO.readTableRows().from(opts.getTable2()))
          .apply("KeyT2", MapElements.into(
            TypeDescriptors.kvs(TypeDescriptors.strings(), TypeDescriptor.of(TableRow.class)))
            .via(r -> KV.of(
              joinKeys.stream().map(k -> Objects.toString(r.get(k), "")).collect(Collectors.joining("|")), r)));

        // Write parse errors
        PCollection<TableRow> errs = PCollectionList.of(ggSplit.get(errTag)).and(plSplit.get(errTag))
          .apply(Flatten.pCollections());
        errs.apply("WriteErrors", BigQueryIO.writeTableRows()
          .to(opts.getErrorOutput())
          .withSchema(new TableSchema().setFields(Arrays.asList(
            new TableFieldSchema().setName("stage").setType("STRING"),
            new TableFieldSchema().setName("raw_data").setType("STRING"),
            new TableFieldSchema().setName("error").setType("STRING"),
            new TableFieldSchema().setName("ts").setType("TIMESTAMP")
          ))));

        // CoGroup all stages
        TupleTag<TableRow> t1=new TupleTag<>("t1"), tg=new TupleTag<>("gg"), tp=new TupleTag<>("pl"), t2=new TupleTag<>("t2");
        PCollection<KV<String,CoGbkResult>> joined = KeyedPCollectionTuple.of(t1,orig)
          .and(tg,gg).and(tp,payload).and(t2,fin)
          .apply("JoinAll", CoGroupByKey.create());

        // Audit & root-cause
        TupleTag<KV<String,long[]>> countTag = new TupleTag<>("counts");
        TupleTag<TableRow> rootTag = new TupleTag<>("rootCause");
        PCollectionTuple multi = joined.apply("AuditAndRootCause",
          ParDo.of(new DoFn<KV<String,CoGbkResult>, KV<String,long[]>>() {
            @ProcessElement public void process(ProcessContext c) {
              String key = c.element().getKey();
              CoGbkResult r = c.element().getValue();
              Map<String,LegacySQLTypeName> types = c.sideInput(typeView);
              boolean p1 = r.getAll(t1).iterator().hasNext();
              boolean p2 = r.getAll(tg).iterator().hasNext();
              boolean p3 = r.getAll(tp).iterator().hasNext();
              boolean p4 = r.getAll(t2).iterator().hasNext();
              for (ColumnConfig cc : cols) {
                String col = cc.getName();
                long eq=0, ne=0;
                for (TableRow a : r.getAll(t1)) for (TableRow b : r.getAll(t2)) {
                  if (equalsTyped(a.get(col), b.get(col), types.get(col))) eq++; else ne++;
                }
                c. output(countTag, KV.of(col+"_"+rule, new long[]{eq,ne}));
                if (ne>0) {
                  String cause = !p1 ? "missing_in_table1"
                    : !p2 ? "missing_in_gg_replica"
                    : !p3 ? "missing_in_payloads_table"
                    : !p4 ? "failed_spanner_insert"
                    : "value_mismatch";
                  TableRow rc = new TableRow();
                  String[] parts = key.split("\\|", -1);
                  for (int i=0; i<joinKeys.size(); i++) rc.set(joinKeys.get(i), parts[i]);
                  rc.set("column", col)
                    .set("root_cause", cause)
                    .set("ts", Instant.now().toString());
                  c.output(rootTag, rc);
                }
              }
            }
          }).withSideInputs(typeView)
            .withOutputTags(countTag, TupleTagList.of(rootTag)));

        // Write audit
        multi.get(countTag)
          .apply(Combine.perKey(new Combine.CombineFn<long[],long[],long[]>(){
            public long[] createAccumulator(){return new long[2];}
            public long[] addInput(long[] a,long[] b){return new long[]{a[0]+b[0],a[1]+b[1]};}
            public long[] mergeAccumulators(Iterable<long[]> it){long e=0,n=0;for(long[]x:it){e+=x[0];n+=x[1];}return new long[]{e,n};}
            public long[] extractOutput(long[]a){return a;}
          }))
          .apply(MapElements.into(TypeDescriptor.of(TableRow.class))
            .via(kv->new TableRow()
              .set("rule",kv.getKey())
              .set("equals_count",kv.getValue()[0])
              .set("not_equals_count",kv.getValue()[1])
              .set("run_date",Instant.now().toString())))
          .apply(BigQueryIO.writeTableRows().to(opts.getAuditOutput())
            .withSchema(new TableSchema().setFields(Arrays.asList(
              new TableFieldSchema().setName("rule").setType("STRING"),
              new TableFieldSchema().setName("equals_count").setType("INTEGER"),
              new TableFieldSchema().setName("not_equals_count").setType("INTEGER"),
              new TableFieldSchema().setName("run_date").setType("TIMESTAMP")
            ))));

        // Write root causes
        multi.get(rootTag)
          .apply(BigQueryIO.writeTableRows().to(opts.getRootCauseOutput())
            .withSchema(new TableSchema().setFields(buildRootSchema(joinKeys))));

        p.run().waitUntilFinish();
    }

    private static List<TableFieldSchema> buildRootSchema(List<String> keys) {
        List<TableFieldSchema> fields = new ArrayList<>();
        for (String k : keys) fields.add(new TableFieldSchema().setName(k).setType("STRING"));
        fields.add(new TableFieldSchema().setName("column").setType("STRING"));
        fields.add(new TableFieldSchema().setName("root_cause").setType("STRING"));
        fields.add(new TableFieldSchema().setName("ts").setType("TIMESTAMP"));
        return fields;
    }

    private static com.google.cloud.bigquery.TableId parseTableId(String ref) {
        String[] parts = ref.split(":");
        String proj = parts[0];
        String[] dsTbl = parts[1].split("\\.");
        return com.google.cloud.bigquery.TableId.of(proj, dsTbl[0], dsTbl[1]);
    }

    private static boolean equalsTyped(Object o1, Object o2, LegacySQLTypeName type) {
        if (o1 == null && o2 == null) return true;
        if (o1 == null || o2 == null) return false;
        try {
            switch (type) {
                case STRING:    return o1.toString().equals(o2.toString());
                case INTEGER:   return ((Number)o1).longValue() == ((Number)o2).longValue();
                case FLOAT:     return Float.compare(((Number)o1).floatValue(), ((Number)o2).floatValue()) == 0;
                case DOUBLE:    return Double.compare(((Number)o1).doubleValue(), ((Number)o2).doubleValue()) == 0;
                case BOOLEAN:   return Boolean.parseBoolean(o1.toString()) == Boolean.parseBoolean(o2.toString());
                case DATE:      return java.time.LocalDate.parse(o1.toString()).equals(java.time.LocalDate.parse(o2.toString()));
                case TIMESTAMP: return Instant.parse(o1.toString()).equals(Instant.parse(o2.toString()));
                default:        return o1.toString().equals(o2.toString());
            }
        } catch (Exception e) {
            return false;
        }
    }
}
