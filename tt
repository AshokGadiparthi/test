---
# config.yaml (host on GCS, passed via --configGcsPath)
dataQuality:
  # Composite join key fields
  joinKeys:
    - cust_id
    - acct_num
    - mtn
  # Dynamic list of any number of comparison columns
  comparison:
    columns: [status, balance, last_update]
    ruleType: "equals"
stages:
  - name: orig
    type: BIGQUERY
    table: "PROJECT:DS.table1"
    jsonRoot: ""       # flat schema
  - name: gg_replica
    type: BIGQUERY
    table: "PROJECT:DS.gg_replica"
    jsonRoot: "/after" # JSON under $.after
  - name: payloads
    type: BIGQUERY
    table: "PROJECT:DS.payloads_table"
    jsonRoot: ""       # JSON root
  - name: new
    type: BIGQUERY
    table: "PROJECT:DS.table2"
    jsonRoot: ""       # flat
outputs:
  audit:       "PROJECT:DS.compare_audit"
  rootCause:   "PROJECT:DS.compare_root_cause"
  parseErrors: "PROJECT:DS.data_quality_parse_errors"
---

// AppConfig.java
package com.trustiq.config;

import java.util.List;

public class AppConfig {
    private DataQualityConfig dataQuality;
    private List<StageConfig> stages;
    private Outputs outputs;

    public DataQualityConfig getDataQuality() { return dataQuality; }
    public void setDataQuality(DataQualityConfig dq) { this.dataQuality = dq; }

    public List<StageConfig> getStages() { return stages; }
    public void setStages(List<StageConfig> stages) { this.stages = stages; }

    public Outputs getOutputs() { return outputs; }
    public void setOutputs(Outputs outputs) { this.outputs = outputs; }

    public static class Outputs {
        private String audit;
        private String rootCause;
        private String parseErrors;

        public String getAudit() { return audit; }
        public void setAudit(String audit) { this.audit = audit; }

        public String getRootCause() { return rootCause; }
        public void setRootCause(String rootCause) { this.rootCause = rootCause; }

        public String getParseErrors() { return parseErrors; }
        public void setParseErrors(String parseErrors) { this.parseErrors = parseErrors; }
    }
}

// DataQualityConfig.java
package com.trustiq.config;

import java.util.List;

public class DataQualityConfig {
    private List<String> joinKeys;
    private ComparisonConfig comparison;

    public List<String> getJoinKeys() { return joinKeys; }
    public void setJoinKeys(List<String> joinKeys) { this.joinKeys = joinKeys; }

    public ComparisonConfig getComparison() { return comparison; }
    public void setComparison(ComparisonConfig comparison) { this.comparison = comparison; }
}

// ComparisonConfig.java
package com.trustiq.config;

import java.util.List;

public class ComparisonConfig {
    private List<String> columns;
    private String ruleType;

    public List<String> getColumns() { return columns; }
    public void setColumns(List<String> columns) { this.columns = columns; }

    public String getRuleType() { return ruleType; }
    public void setRuleType(String ruleType) { this.ruleType = ruleType; }
}

// StageConfig.java
package com.trustiq.config;

public class StageConfig {
    private String name;
    private String type;
    private String table;
    private String jsonRoot;

    public String getName() { return name; }
    public void setName(String name) { this.name = name; }

    public String getType() { return type; }
    public void setType(String type) { this.type = type; }

    public String getTable() { return table; }
    public void setTable(String table) { this.table = table; }

    public String getJsonRoot() { return jsonRoot; }
    public void setJsonRoot(String jsonRoot) { this.jsonRoot = jsonRoot; }
}

---

// DataQualityPipeline.java
package com.trustiq.pipeline;

import com.fasterxml.jackson.databind.JsonNode;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.google.api.services.bigquery.model.*;
import com.google.cloud.bigquery.LegacySQLTypeName;
import com.trustiq.config.*;
import org.apache.beam.runners.dataflow.DataflowRunner;
import org.apache.beam.sdk.Pipeline;
import org.apache.beam.sdk.io.gcp.bigquery.BigQueryIO;
import org.apache.beam.sdk.options.*;
import org.apache.beam.sdk.transforms.*;
import org.apache.beam.sdk.transforms.join.CoGbkResult;
import org.apache.beam.sdk.transforms.join.KeyedPCollectionTuple;
import org.apache.beam.sdk.transforms.join.TupleTag;
import org.apache.beam.sdk.values.*;

import java.io.IOException;
import java.time.Instant;
import java.util.*;
import java.util.stream.Collectors;

public class DataQualityPipeline {

    public interface Options extends PipelineOptions, DataflowPipelineOptions {
        @Description("GCS URI to config.yaml")
        @Validation.Required String getConfigGcsPath(); void setConfigGcsPath(String v);
        @Description("BQ table1: legacy source")
        @Validation.Required String getTable1(); void setTable1(String v);
        @Description("BQ table2: final Cassandra BQ")
        @Validation.Required String getTable2(); void setTable2(String v);
        @Description("BQ gg_replica JSON source")
        @Validation.Required String getGgTable(); void setGgTable(String v);
        @Description("BQ payloads_table JSON source")
        @Validation.Required String getPayloadTable(); void setPayloadTable(String v);
        @Description("BQ output for audit counts")
        @Validation.Required String getAuditOutput(); void setAuditOutput(String v);
        @Description("BQ output for root-cause details")
        @Validation.Required String getRootCauseOutput(); void setRootCauseOutput(String v);
        @Description("BQ output for JSON parse errors")
        @Validation.Required String getErrorOutput(); void setErrorOutput(String v);
    }

    public static void main(String[] args) {
        Options opts = PipelineOptionsFactory.fromArgs(args).withValidation().as(Options.class);
        opts.setRunner(DataflowRunner.class);

        AppConfig cfg = ConfigLoader.load(opts.getConfigGcsPath());
        DataQualityConfig dq = cfg.getDataQuality();
        List<String> joinKeys = dq.getJoinKeys();
        List<String> cols = dq.getComparison().getColumns();
        String rule = dq.getComparison().getRuleType();

        // Fetch schema types for table1
        com.google.cloud.bigquery.BigQuery bq = com.google.cloud.bigquery.BigQueryOptions.getDefaultInstance().getService();
        com.google.cloud.bigquery.TableId tid = parseTableId(opts.getTable1());
        com.google.cloud.bigquery.Schema schema = bq.getTable(tid).getDefinition().getSchema();
        List<KV<String,LegacySQLTypeName>> typeList = schema.getFields().stream()
            .map(f -> KV.of(f.getName(), f.getType()))
            .collect(Collectors.toList());

        Pipeline p = Pipeline.create(opts);
        PCollectionView<Map<String,LegacySQLTypeName>> typeView = p
            .apply("TypeList", Create.of(typeList))
            .apply("TypeMap", View.asMap());

        ObjectMapper mapper = new ObjectMapper();
        final TupleTag<TableRow> errTag = new TupleTag<>("errors");

        // Extract JSON payload into structured TableRow
        class ExtractFn extends DoFn<TableRow, KV<String,TableRow>> {
            private final String jsonRoot;
            ExtractFn(String jsonRoot) { this.jsonRoot = jsonRoot; }

            @ProcessElement
            public void process(ProcessContext c) {
                TableRow row = c.element();
                try {
                    JsonNode root = mapper.readTree((String) row.get("DATA"));
                    JsonNode data = jsonRoot.isEmpty() ? root : root.at(jsonRoot);
                    String cust  = data.path("cust_id").asText(null);
                    String acct  = data.path("acct_num").asText(null);
                    String mtn   = data.path("mtn").asText(null);
                    String key   = String.join("|", cust, acct, mtn);

                    TableRow out = new TableRow()
                        .set("cust_id", cust)
                        .set("acct_num", acct)
                        .set("mtn", mtn);
                    for (String col : cols) {
                        out.set(col, data.path(col).asText(null));
                    }
                    c.output(KV.of(key, out));
                } catch (IOException e) {
                    c.output(errTag, new TableRow()
                        .set("stage", jsonRoot)
                        .set("raw_data", row.get("DATA"))
                        .set("error", e.getMessage())
                        .set("ts", Instant.now().toString()));
                }
            }
        }

        // Read & key original table
        PCollection<KV<String,TableRow>> orig = p.apply("ReadOrig",
            BigQueryIO.readTableRows().from(opts.getTable1()))
          .apply("KeyOrig", MapElements.into(
            TypeDescriptors.kvs(TypeDescriptors.strings(), TypeDescriptor.of(TableRow.class)))
          .via(r -> KV.of(
            joinKeys.stream().map(k -> Objects.toString(r.get(k), "")).collect(Collectors.joining("|")),
            r)));

        // Read & extract gg_replica JSON
        PCollectionTuple ggSplit = p.apply("ReadGG",
            BigQueryIO.readTableRows().from(opts.getGgTable()))
          .apply("ExtractGG",
            ParDo.of(new ExtractFn("/after"))
              .withOutputTags(new TupleTag<KV<String,TableRow>>() {}, TupleTagList.of(errTag)));
        PCollection<KV<String,TableRow>> gg = ggSplit.get(new TupleTag<KV<String,TableRow>>(){});

        // Read & extract payloads_table JSON
        PCollectionTuple plSplit = p.apply("ReadPL",
            BigQueryIO.readTableRows().from(opts.getPayloadTable()))
          .apply("ExtractPL",
            ParDo.of(new ExtractFn(""))
              .withOutputTags(new TupleTag<KV<String,TableRow>>() {}, TupleTagList.of(errTag)));
        PCollection<KV<String,TableRow>> pl = plSplit.get(new TupleTag<KV<String,TableRow>>(){});

        // Read & key final table
        PCollection<KV<String,TableRow>> fin = p.apply("ReadNew",
            BigQueryIO.readTableRows().from(opts.getTable2()))
          .apply("KeyNew", MapElements.into(
            TypeDescriptors.kvs(TypeDescriptors.strings(), TypeDescriptor.of(TableRow.class)))
          .via(r -> KV.of(
            joinKeys.stream().map(k -> Objects.toString(r.get(k), "")).collect(Collectors.joining("|")),
            r)));

        // Merge parse errors and write
        PCollection<TableRow> errs = PCollectionList.of(ggSplit.get(errTag))
          .and(plSplit.get(errTag))
          .apply(Flatten.pCollections());
        errs.apply("WriteErrors",
          BigQueryIO.writeTableRows().to(opts.getErrorOutput())
            .withSchema(new TableSchema().setFields(Arrays.asList(
              new TableFieldSchema().setName("stage").setType("STRING"),
              new TableFieldSchema().setName("raw_data").setType("STRING"),
              new TableFieldSchema().setName("error").setType("STRING"),
              new TableFieldSchema().setName("ts").setType("TIMESTAMP")
            ))));

        // CoGroup all four stages
        TupleTag<TableRow> t1 = new TupleTag<>("t1"), tg=new TupleTag<>("gg"), tp2=new TupleTag<>("pl"), t2=new TupleTag<>("t2");
        PCollection<KV<String,CoGbkResult>> joined = KeyedPCollectionTuple.of(t1, orig)
          .and(tg, gg).and(tp2, pl).and(t2, fin)
          .apply("JoinAllStages", CoGroupByKey.create());

        // Compare & root-cause
        TupleTag<KV<String,long[]>> countTag = new TupleTag<>("counts");
        TupleTag<TableRow> rootTag = new TupleTag<>("rootCause");
        PCollectionTuple multi = joined.apply("AuditAndRootCause",
          ParDo.of(new DoFn<KV<String,CoGbkResult>, KV<String,long[]>>() {
            @ProcessElement public void process(ProcessContext c) {
              String key = c.element().getKey();
              CoGbkResult r = c.element().getValue();
              Map<String,LegacySQLTypeName> tv = c.sideInput(typeView);

              boolean p1 = r.getAll(t1).iterator().hasNext();
              boolean p2 = r.getAll(tg).iterator().hasNext();
              boolean p3 = r.getAll(tp2).iterator().hasNext();
              boolean p4 = r.getAll(t2).iterator().hasNext();

              for (String col : cols) {
                long eq=0, ne=0;
                for (TableRow a : r.getAll(t1)) {
                  for (TableRow b : r.getAll(t2)) {
                    if (equalsTyped(a.get(col), b.get(col), tv.get(col))) eq++; else ne++;
                  }
                }
                c.output(countTag, KV.of(col+"_"+rule, new long[]{eq,ne}));
                if (ne>0) {
                  String cause = !p1 ? "missing_in_table1"
                    : !p2 ? "missing_in_gg_replica"
                    : !p3 ? "missing_in_payloads_table"
                    : !p4 ? "failed_spanner_insert"
                    : "value_mismatch";
                  TableRow rc = new TableRow();
                  String[] parts = key.split("\\|", -1);
                  for (int i=0; i<joinKeys.size(); i++) rc.set(joinKeys.get(i), parts[i]);
                  rc.set("column", col)
                    .set("root_cause", cause)
                    .set("ts", Instant.now().toString());
                  c.output(rootTag, rc);
                }
              }
            }
          }).withSideInputs(typeView)
            .withOutputTags(countTag, TupleTagList.of(rootTag)));

        // Write audit counts
        multi.get(countTag)
          .apply("SumCounts", Combine.perKey(new Combine.CombineFn<long[],long[],long[]>() {
            public long[] createAccumulator() { return new long[]{0,0}; }
            public long[] addInput(long[] acc, long[] in) { return new long[]{acc[0]+in[0], acc[1]+in[1]}; }
            public long[] mergeAccumulators(Iterable<long[]> it) {
              long e=0,n=0; for (long[] a : it) { e+=a[0]; n+=a[1]; } return new long[]{e,n}; }
            public long[] extractOutput(long[] acc) { return acc; }
          }))
          .apply("ToAuditRow", MapElements.into(TypeDescriptor.of(TableRow.class))
            .via(kv -> new TableRow()
              .set("rule",           kv.getKey())
              .set("equals_count",   kv.getValue()[0])
              .set("not_equals_count", kv.getValue()[1])
              .set("run_date",       Instant.now().toString())))
          .apply("WriteAudit", BigQueryIO.writeTableRows()
            .to(opts.getAuditOutput())
            .withSchema(new TableSchema().setFields(Arrays.asList(
              new TableFieldSchema().setName("rule").setType("STRING"),
              new TableFieldSchema().setName("equals_count").setType("INTEGER"),
              new TableFieldSchema().setName("not_equals_count").setType("INTEGER"),
              new TableFieldSchema().setName("run_date").setType("TIMESTAMP")
            ))));

        // Write root-cause details
        multi.get(rootTag)
          .apply("WriteRoots", BigQueryIO.writeTableRows()
            .to(opts.getRootCauseOutput())
            .withSchema(new TableSchema().setFields(buildRootSchema(joinKeys))));

        p.run().waitUntilFinish();
    }

    private static List<TableFieldSchema> buildRootSchema(List<String> keys) {
        List<TableFieldSchema> fs = new ArrayList<>();
        for (String k : keys) fs.add(new TableFieldSchema().setName(k).setType("STRING"));
        fs.add(new TableFieldSchema().setName("column").setType("STRING"));
        fs.add(new TableFieldSchema().setName("root_cause").setType("STRING"));
        fs.add(new TableFieldSchema().setName("ts").setType("TIMESTAMP"));
        return fs;
    }

    private static com.google.cloud.bigquery.TableId parseTableId(String ref) {
        String[] p = ref.split(":");
        String proj = p[0];
        String[] ds = p[1].split("\\.");
        return com.google.cloud.bigquery.TableId.of(proj, ds[0], ds[1]);
    }

    private static boolean equalsTyped(Object o1, Object o2, LegacySQLTypeName type) {
        if (o1 == null && o2 == null) return true;
        if (o1 == null || o2 == null) return false;
        try {
            switch (type) {
                case STRING:    return o1.toString().equals(o2.toString());
                case INTEGER:   return ((Number)o1).longValue() == ((Number)o2).longValue();
                case FLOAT:     return Float.compare(((Number)o1).floatValue(), ((Number)o2).floatValue()) == 0;
                case DOUBLE:    return Double.compare(((Number)o1).doubleValue(), ((Number)o2).doubleValue()) == 0;
                case BOOLEAN:   return Boolean.parseBoolean(o1.toString()) == Boolean.parseBoolean(o2.toString());
                case DATE:      return java.time.LocalDate.parse(o1.toString()).equals(java.time.LocalDate.parse(o2.toString()));
                case TIMESTAMP: return Instant.parse(o1.toString()).equals(Instant.parse(o2.toString()));
                default:        return o1.toString().equals(o2.toString());
            }
        } catch (Exception e) {
            return false;
        }
    }
}
