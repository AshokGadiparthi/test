/*
 * A production-ready Dataflow pipeline that reads JSON messages from a Pub/Sub topic,
 * aggregates records by a composite key (derived dynamically based on event_name)
 * within a 30-second window, and then for each grouped key performs a lookup in Spanner
 * to either update or insert a record with the aggregated payload.
 *
 * For event types:
 *   - "A" or "B":  use cust_id and acct_no as the key and upsert into table "acct_prfl"
 *                   (with mtn set to null)
 *   - "C", "D", "E", or "F": use cust_id and mtn as the key and upsert into table "acct_line_prfl"
 *
 * Required Maven dependencies (versions may vary):
 *   - org.apache.beam:beam-sdks-java-core
 *   - org.apache.beam:beam-runners-google-cloud-dataflow-java
 *   - com.google.cloud:google-cloud-spanner
 *   - com.google.code.gson:gson
 */
package com.example.dataflow;

import com.google.api.gax.rpc.ApiException;
import com.google.cloud.Timestamp;
import com.google.cloud.spanner.DatabaseClient;
import com.google.cloud.spanner.DatabaseId;
import com.google.cloud.spanner.Mutation;
import com.google.cloud.spanner.ResultSet;
import com.google.cloud.spanner.Spanner;
import com.google.cloud.spanner.SpannerOptions;
import com.google.cloud.spanner.Statement;
import com.google.gson.Gson;
import java.util.ArrayList;
import java.util.Collections;
import java.util.Comparator;
import java.util.List;
import java.util.UUID;
import org.apache.beam.sdk.Pipeline;
import org.apache.beam.sdk.options.Description;
import org.apache.beam.sdk.options.PipelineOptions;
import org.apache.beam.sdk.options.PipelineOptionsFactory;
import org.apache.beam.sdk.transforms.DoFn;
import org.apache.beam.sdk.transforms.GroupByKey;
import org.apache.beam.sdk.transforms.MapElements;
import org.apache.beam.sdk.transforms.ParDo;
import org.apache.beam.sdk.transforms.windowing.FixedWindows;
import org.apache.beam.sdk.transforms.windowing.Window;
import org.apache.beam.sdk.values.KV;
import org.apache.beam.sdk.values.TypeDescriptor;
import org.apache.beam.sdk.values.TypeDescriptors;
import org.joda.time.Duration;

/** Main class for the Pub/Sub to Spanner aggregator pipeline. */
public class PubSubToSpannerAggregator {

  /** Pipeline options for the job. */
  public interface PubSubToSpannerOptions extends PipelineOptions {
    @Description("Input Pub/Sub topic of the form projects/<PROJECT>/topics/<TOPIC>")
    String getInputTopic();
    void setInputTopic(String value);

    @Description("Google Cloud Spanner Project ID")
    String getSpannerProjectId();
    void setSpannerProjectId(String value);

    @Description("Google Cloud Spanner Instance ID")
    String getSpannerInstanceId();
    void setSpannerInstanceId(String value);

    @Description("Google Cloud Spanner Database ID")
    String getSpannerDatabaseId();
    void setSpannerDatabaseId(String value);
  }

  /**
   * POJO for incoming transaction messages.
   *
   * Expected JSON format examples:
   *
   * For events A or B (acct_prfl):
   * <pre>
   * {
   *   "event_name": "A",
   *   "cust_id": "customer123",
   *   "acct_no": "acct123",
   *   "payload": "{ ... }",
   *   "ops_ts": 1672500000000
   * }
   * </pre>
   *
   * For events C, D, E or F (acct_line_prfl):
   * <pre>
   * {
   *   "event_name": "C",
   *   "cust_id": "customer123",
   *   "mtn": "mtn_value",
   *   "acct_no": "acct123",    // optional additional field
   *   "payload": "{ ... }",
   *   "ops_ts": 1672500000000
   * }
   * </pre>
   *
   * The {@code fromJson()} method will also set the extra property {@code table_name}
   * as follows:
   *   - If event_name is "A" or "B": table_name = "acct_prfl" (and mtn is set to null)
   *   - If event_name is "C", "D", "E" or "F": table_name = "acct_line_prfl"
   */
  public static class TransactionMessage {
    String event_name;
    String cust_id;
    String acct_no;
    String mtn;
    String payload;
    long ops_ts; // timestamp in milliseconds
    // Extra property: indicates which Spanner table to upsert into.
    String table_name;

    public String getEventName() { return event_name; }
    public String getCustId() { return cust_id; }
    public String getAcctNo() { return acct_no; }
    public String getMtn() { return mtn; }
    public String getPayload() { return payload; }
    public long getOpsTs() { return ops_ts; }
    public String getTableName() { return table_name; }

    /**
     * Parses a JSON string into a TransactionMessage POJO.
     * Also sets the table_name and adjusts fields based on event_name.
     */
    public static TransactionMessage fromJson(String json) {
      TransactionMessage message = new Gson().fromJson(json, TransactionMessage.class);
      // Determine table_name based on event_name.
      if ("A".equalsIgnoreCase(message.event_name) || "B".equalsIgnoreCase(message.event_name)) {
        message.table_name = "acct_prfl";
        // For A/B events, mtn is not applicable.
        message.mtn = null;
      } else if ("C".equalsIgnoreCase(message.event_name)
          || "D".equalsIgnoreCase(message.event_name)
          || "E".equalsIgnoreCase(message.event_name)
          || "F".equalsIgnoreCase(message.event_name)) {
        message.table_name = "acct_line_prfl";
        // For these events, acct_no might be present but the grouping key is based on cust_id and mtn.
      } else {
        // Default or unknown event types may be handled here.
        message.table_name = "unknown";
      }
      return message;
    }
  }

  /**
   * DoFn to aggregate a set of TransactionMessages for the same composite key.
   *
   * Aggregation logic:
   * - Sort records by their ops_ts.
   * - Concatenate their payloads (separated by a space).
   * - For acct_prfl records, use cust_id and acct_no; for acct_line_prfl, use cust_id and mtn.
   */
  public static class AggregateMessagesFn
      extends DoFn<KV<String, Iterable<TransactionMessage>>, KV<String, TransactionMessage>> {

    @ProcessElement
    public void processElement(ProcessContext c) {
      String compositeKey = c.element().getKey();
      Iterable<TransactionMessage> messagesIterable = c.element().getValue();
      List<TransactionMessage> messages = new ArrayList<>();
      for (TransactionMessage msg : messagesIterable) {
        messages.add(msg);
      }
      // Sort messages by ops_ts (ascending)
      Collections.sort(messages, Comparator.comparingLong(TransactionMessage::getOpsTs));

      // Aggregate payloads (concatenation with a space separator)
      StringBuilder aggregatedPayload = new StringBuilder();
      for (TransactionMessage msg : messages) {
        aggregatedPayload.append(msg.getPayload()).append(" ");
      }

      TransactionMessage aggregatedMessage = new TransactionMessage();
      // All messages in this group share the same key fields and table_name.
      aggregatedMessage.cust_id = messages.get(0).getCustId();
      aggregatedMessage.table_name = messages.get(0).getTableName();
      // Set keys based on table type.
      if ("acct_prfl".equals(aggregatedMessage.table_name)) {
        aggregatedMessage.acct_no = messages.get(0).getAcctNo();
        aggregatedMessage.mtn = null;
      } else if ("acct_line_prfl".equals(aggregatedMessage.table_name)) {
        aggregatedMessage.mtn = messages.get(0).getMtn();
        // Optionally, preserve acct_no if needed.
        aggregatedMessage.acct_no = messages.get(0).getAcctNo();
      }
      aggregatedMessage.payload = aggregatedPayload.toString().trim();
      // Use the latest timestamp among the messages.
      aggregatedMessage.ops_ts = messages.get(messages.size() - 1).getOpsTs();

      c.output(KV.of(compositeKey, aggregatedMessage));
    }
  }

  /**
   * DoFn that performs a lookup in Spanner (using keys based on table_name) and then upserts
   * the aggregated record. If a record already exists (i.e. a UUID is found), it reuses that UUID;
   * otherwise, a new UUID is generated.
   */
  public static class SpannerUpsertFn extends DoFn<KV<String, TransactionMessage>, Void> {

    private transient Spanner spanner;
    private transient DatabaseClient dbClient;
    private final String projectId;
    private final String instanceId;
    private final String databaseId;

    public SpannerUpsertFn(String projectId, String instanceId, String databaseId) {
      this.projectId = projectId;
      this.instanceId = instanceId;
      this.databaseId = databaseId;
    }

    @Setup
    public void setup() {
      SpannerOptions options = SpannerOptions.newBuilder().build();
      spanner = options.getService();
      DatabaseId db = DatabaseId.of(projectId, instanceId, databaseId);
      dbClient = spanner.getDatabaseClient(db);
    }

    @Teardown
    public void teardown() {
      if (spanner != null) {
        spanner.close();
      }
    }

    @ProcessElement
    public void processElement(ProcessContext c) {
      TransactionMessage msg = c.element().getValue();
      String tableName = msg.getTableName();
      String query;
      Statement.Builder stmtBuilder;

      if ("acct_prfl".equals(tableName)) {
        // For acct_prfl, lookup by cust_id and acct_no.
        query = String.format("SELECT UUID FROM %s WHERE cust_id = @cust_id AND acct_no = @acct_no", tableName);
        stmtBuilder = Statement.newBuilder(query)
            .bind("cust_id").to(msg.getCustId())
            .bind("acct_no").to(msg.getAcctNo());
      } else if ("acct_line_prfl".equals(tableName)) {
        // For acct_line_prfl, lookup by cust_id and mtn.
        query = String.format("SELECT UUID FROM %s WHERE cust_id = @cust_id AND mtn = @mtn", tableName);
        stmtBuilder = Statement.newBuilder(query)
            .bind("cust_id").to(msg.getCustId())
            .bind("mtn").to(msg.getMtn());
      } else {
        System.err.println("Unknown table type: " + tableName);
        return;
      }
      Statement statement = stmtBuilder.build();

      String existingUUID = null;
      try (ResultSet resultSet = dbClient.singleUse().executeQuery(statement)) {
        if (resultSet.next()) {
          existingUUID = resultSet.getString("UUID");
        }
      } catch (ApiException e) {
        System.err.println("Error during Spanner lookup: " + e.getMessage());
        return;
      }

      // Prepare the upsert mutation.
      Mutation.WriteBuilder mutationBuilder = Mutation.newInsertOrUpdateBuilder(tableName)
          .set("cust_id").to(msg.getCustId())
          .set("payload").to(msg.getPayload())
          // Convert ops_ts from milliseconds to Spanner Timestamp (microseconds)
          .set("ops_ts").to(Timestamp.ofTimeMicroseconds(msg.getOpsTs() * 1000L));

      if ("acct_prfl".equals(tableName)) {
        mutationBuilder.set("acct_no").to(msg.getAcctNo());
        // For acct_prfl, mtn is not used.
      } else if ("acct_line_prfl".equals(tableName)) {
        mutationBuilder.set("mtn").to(msg.getMtn());
        // Optionally, store acct_no if available.
        if (msg.getAcctNo() != null) {
          mutationBuilder.set("acct_no").to(msg.getAcctNo());
        }
      }

      if (existingUUID != null) {
        mutationBuilder.set("UUID").to(existingUUID);
      } else {
        mutationBuilder.set("UUID").to(UUID.randomUUID().toString());
      }
      Mutation mutation = mutationBuilder.build();

      try {
        dbClient.write(Collections.singletonList(mutation));
      } catch (ApiException e) {
        System.err.println("Error during Spanner upsert: " + e.getMessage());
      }
    }
  }

  public static void main(String[] args) {
    // Parse pipeline options from the command line.
    PubSubToSpannerOptions options =
        PipelineOptionsFactory.fromArgs(args).withValidation().as(PubSubToSpannerOptions.class);
    Pipeline p = Pipeline.create(options);

    p.apply("ReadFromPubSub", 
              org.apache.beam.sdk.io.gcp.pubsub.PubsubIO.readStrings().fromTopic(options.getInputTopic()))
        // Parse each JSON message into a TransactionMessage POJO.
        .apply("ParseMessages", ParDo.of(new DoFn<String, TransactionMessage>() {
          @ProcessElement
          public void processElement(ProcessContext c) {
            try {
              TransactionMessage msg = TransactionMessage.fromJson(c.element());
              c.output(msg);
            } catch (Exception e) {
              // In production, log the error and consider sending bad messages to a dead-letter topic.
              System.err.println("Failed to parse message: " + e.getMessage());
            }
          }
        }))
        // Map each message to a KV pair with a composite key.
        // For acct_prfl: key = "acct_prfl_custid_acctno"
        // For acct_line_prfl: key = "acct_line_prfl_custid_mtn"
        .apply("MapToKV",
            MapElements.into(
                TypeDescriptors.kvs(TypeDescriptors.strings(), TypeDescriptor.of(TransactionMessage.class)))
                .via(msg -> {
                  String key;
                  if ("acct_prfl".equals(msg.getTableName())) {
                    key = msg.getTableName() + "_" + msg.getCustId() + "_" + msg.getAcctNo();
                  } else if ("acct_line_prfl".equals(msg.getTableName())) {
                    key = msg.getTableName() + "_" + msg.getCustId() + "_" + msg.getMtn();
                  } else {
                    key = "unknown_" + msg.getCustId();
                  }
                  return KV.of(key, msg);
                }))
        // Apply fixed windowing of 30 seconds.
        .apply("WindowIntoFixed", Window.<KV<String, TransactionMessage>>into(FixedWindows.of(Duration.standardSeconds(30))))
        // Group messages by composite key.
        .apply("GroupByKey", GroupByKey.create())
        // Aggregate messages for each key (ordering by ops_ts and concatenating payloads).
        .apply("AggregateMessages", ParDo.of(new AggregateMessagesFn()))
        // For each aggregated record, perform a Spanner lookup and upsert.
        .apply("UpsertToSpanner", ParDo.of(new SpannerUpsertFn(
            options.getSpannerProjectId(),
            options.getSpannerInstanceId(),
            options.getSpannerDatabaseId())));

    p.run().waitUntilFinish();
  }
}
