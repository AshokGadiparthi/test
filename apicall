import com.google.cloud.storage.Storage;
import com.google.cloud.storage.StorageOptions;
import com.google.cloud.storage.Blob;
import com.google.cloud.storage.BlobId;
import org.apache.beam.sdk.Pipeline;
import org.apache.beam.sdk.io.TextIO;
import org.apache.beam.sdk.options.PipelineOptionsFactory;
import org.apache.beam.sdk.options.ValueProvider;
import org.apache.beam.sdk.transforms.Create;
import org.apache.beam.sdk.transforms.ParDo;
import org.apache.beam.sdk.values.PCollection;

public class DataflowTemplateWithOptionalFile {

    public interface MyPipelineOptions extends DataflowPipelineOptions {
        ValueProvider<String> getInputFilePattern();
        void setInputFilePattern(ValueProvider<String> inputFilePattern);
    }

    public static void main(String[] args) {
        MyPipelineOptions options = PipelineOptionsFactory.fromArgs(args)
                .withValidation()
                .as(MyPipelineOptions.class);

        Pipeline pipeline = Pipeline.create(options);

        // Placeholder pattern for template creation
        String dummyPattern = "gs://dummy-bucket/path-to-nonexistent-file.txt";
        
        // Use the dummy pattern at template creation time (if input file not yet available)
        ValueProvider<String> inputFilePattern = options.getInputFilePattern().isAccessible() ?
                options.getInputFilePattern() : ValueProvider.StaticValueProvider.of(dummyPattern);

        PCollection<String> input = pipeline.apply("Check Input File",
                Create.of("Checking if input file exists...")
        );

        // Check if the file exists at runtime using the provided input pattern
        PCollection<String> fileExists = input.apply("Check GCS File", 
                ParDo.of(new CheckFileExists(inputFilePattern)));

        // If the file exists, read from it, otherwise skip
        PCollection<String> lines = fileExists.apply("Read File",
                TextIO.read().from(inputFilePattern).withCompression(TextIO.Compression.GZIP));

        // Process the data
        lines.apply("Process Data", ParDo.of(new ProcessDataFn()));

        pipeline.run();
    }

    // A DoFn to check if a file exists on GCS at runtime
    static class CheckFileExists extends DoFn<String, String> {
        private final ValueProvider<String> filePattern;

        public CheckFileExists(ValueProvider<String> filePattern) {
            this.filePattern = filePattern;
        }

        @ProcessElement
        public void processElement(ProcessContext c) {
            Storage storage = StorageOptions.getDefaultInstance().getService();
            String pattern = filePattern.get();

            // Replace "your-bucket-name" and "path-to-file" with actual GCS path logic
            Blob blob = storage.get(BlobId.of("your-bucket-name", "path-to-file"));

            if (blob != null && blob.exists()) {
                c.output(pattern);  // File exists, output the pattern for reading
            } else {
                System.out.println("File does not exist, skipping...");
            }
        }
    }

    // Dummy processing function
    static class ProcessDataFn extends DoFn<String, Void> {
        @ProcessElement
        public void processElement(ProcessContext c) {
            // Your processing logic here
            System.out.println("Processing: " + c.element());
        }
    }
}
