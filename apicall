import org.apache.beam.sdk.Pipeline;
import org.apache.beam.sdk.io.gcp.bigquery.BigQueryIO;
import org.apache.beam.sdk.options.PipelineOptions;
import org.apache.beam.sdk.options.PipelineOptionsFactory;
import org.apache.beam.sdk.transforms.DoFn;
import org.apache.beam.sdk.transforms.ParDo;
import org.apache.beam.sdk.values.PCollection;
import redis.clients.jedis.Jedis;
import com.google.api.services.bigquery.model.TableRow;
import java.util.Set;

public class BigQueryToRedis {

    // Apache Beam DoFn to Write ref_col values to Redis
    static class WriteToRedisFn extends DoFn<TableRow, Void> {
        private transient Jedis jedis;
        private static final String REDIS_SET_KEY = "ref_col_set";

        @Setup
        public void setup() {
            jedis = new Jedis("your-redis-host", 6379);  // Replace with your Redis host
        }

        @ProcessElement
        public void processElement(ProcessContext c) {
            TableRow row = c.element();
            String refColValue = (String) row.get("ref_col");

            if (refColValue != null) {
                jedis.sadd(REDIS_SET_KEY, refColValue);  // Store in Redis Set
            }
        }

        @FinishBundle
        public void finishBundle() {
            // Get total count of records stored
            long totalCount = jedis.scard(REDIS_SET_KEY);
            System.out.println("âœ… Total records stored in Redis Set: " + totalCount);

            // Fetch 5 random sample values
            Set<String> sampleValues = jedis.srandmember(REDIS_SET_KEY, 5);
            System.out.println("ðŸ“Œ Sample records stored in Redis: " + sampleValues);
        }

        @Teardown
        public void teardown() {
            jedis.close();
        }
    }

    public static void main(String[] args) {
        PipelineOptions options = PipelineOptionsFactory.fromArgs(args).withValidation().create();
        Pipeline pipeline = Pipeline.create(options);

        // Read all rows from BigQuery table (without SQL query)
        PCollection<TableRow> rows = pipeline.apply("ReadFromBigQuery",
                BigQueryIO.readTableRows()
                        .from("your_project.your_dataset.employee"));  // Replace with your table details

        // Store the ref_col values in Redis
        rows.apply("WriteToRedis", ParDo.of(new WriteToRedisFn()));

        pipeline.run().waitUntilFinish();
    }
}
