pip install google-cloud-spanner


import concurrent.futures
import random
from google.cloud import spanner
from google.cloud.spanner_v1 import KeySet

# Spanner setup
instance_id = "your-instance-id"
database_id = "your-database-id"
table_name = "SpannerToPubSubCDC"

# Establish Spanner connection
spanner_client = spanner.Client()
instance = spanner_client.instance(instance_id)
database = instance.database(database_id)

# Define the percentages for operations
total_operations = 1_000_000
insert_percentage = 0.30
update_percentage = 0.40
delete_percentage = 0.30

insert_count = int(total_operations * insert_percentage)
update_count = int(total_operations * update_percentage)
delete_count = int(total_operations * delete_percentage)


# Function to generate mock insert SQL statements
def insert_data():
    with database.batch() as batch:
        for i in range(insert_count):
            cust_id = i + 1
            acct_num = random.randint(100000, 999999)
            selected_mtn = random.randint(5000000000, 5999999999)
            mtn = random.randint(5000000000, 5999999999)
            order_num = random.randint(200000, 299999)

            # Insert query
            batch.insert(
                table=table_name,
                columns=("cust_id", "acct_num", "selected_MTN", "mtn", "order_num"),
                values=[(cust_id, acct_num, selected_mtn, mtn, order_num)],
            )


# Function to generate mock update SQL statements
def update_data():
    with database.snapshot() as snapshot:
        with database.batch() as batch:
            for i in range(update_count):
                cust_id = random.randint(1, insert_count)
                new_selected_mtn = random.randint(5000000000, 5999999999)
                new_mtn = random.randint(5000000000, 5999999999)

                # Update query
                batch.update(
                    table=table_name,
                    columns=("cust_id", "selected_MTN", "mtn"),
                    values=[(cust_id, new_selected_mtn, new_mtn)],
                )


# Function to generate mock delete SQL statements
def delete_data():
    with database.snapshot() as snapshot:
        with database.batch() as batch:
            for i in range(delete_count):
                cust_id = random.randint(1, insert_count)

                # Delete query
                batch.delete(table=table_name, keyset=KeySet(keys=[(cust_id,)]))


# Function to run tasks in parallel using a ThreadPoolExecutor
def run_operations():
    with concurrent.futures.ThreadPoolExecutor() as executor:
        # Submit parallel tasks
        insert_task = executor.submit(insert_data)
        update_task = executor.submit(update_data)
        delete_task = executor.submit(delete_data)

        # Wait for all tasks to complete
        concurrent.futures.wait([insert_task, update_task, delete_task])


if __name__ == "__main__":
    run_operations()
    print("All operations completed.")
