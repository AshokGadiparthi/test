Great — here are the exact SQLs you need:

1) MERGE SQL to maintain 
ops_airflow_dag_current_status


Run this from your 15-min monitoring DAG (recommended), or as a separate scheduled query.



Option A (best): MERGE from the last 24h facts
MERGE `vz-it-pr-hukv-cdwldo-0.ops_monitoring.ops_airflow_dag_current_status` T
USING (
  SELECT
    dag_id,
    ARRAY_AGG(
      STRUCT(snapshot_ts, state, run_id, duration_sec, airflow_url)
      ORDER BY snapshot_ts DESC
      LIMIT 1
    )[OFFSET(0)] AS last
  FROM `vz-it-pr-hukv-cdwldo-0.ops_monitoring.ops_airflow_dag_run_fact`
  WHERE snapshot_ts >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 24 HOUR)
  GROUP BY dag_id
) S
ON T.dag_id = S.dag_id
WHEN MATCHED THEN UPDATE SET
  T.last_seen   = S.last.snapshot_ts,
  T.state       = S.last.state,
  T.run_id      = S.last.run_id,
  T.duration_sec= S.last.duration_sec,
  T.airflow_url = S.last.airflow_url,
  T.updated_ts  = CURRENT_TIMESTAMP()
WHEN NOT MATCHED THEN INSERT
  (dag_id, last_seen, state, run_id, duration_sec, airflow_url, updated_ts)
VALUES
  (S.dag_id, S.last.snapshot_ts, S.last.state, S.last.run_id, S.last.duration_sec, S.last.airflow_url, CURRENT_TIMESTAMP());
Option B (faster/cheaper): MERGE only “recent window” (last 2h)


Same SQL, just change 24 HOUR → 2 HOUR.

2) Master “Consolidated Sheet” query (one table like your Excel)


This produces one row per DAG with:

registry info (owners, tags, criticality, SLA)

latest state/run/duration

open incident severity/category

impacted downstream count

flags: stale, failed, slow risk

WITH reg AS (
  SELECT
    dag_id,
    airflow_tags,
    owner_emails,
    is_critical,
    sla_minutes,
    enabled,
    is_paused,
    is_egress,
    hold_if_failed_dags
  FROM `vz-it-pr-hukv-cdwldo-0.ops_monitoring.ops_airflow_dag_registry`
  WHERE enabled = TRUE
),
cur AS (
  SELECT
    dag_id,
    last_seen,
    state,
    run_id,
    duration_sec,
    airflow_url
  FROM `vz-it-pr-hukv-cdwldo-0.ops_monitoring.ops_airflow_dag_current_status`
),
inc AS (
  SELECT
    dag_id,
    ARRAY_AGG(
      STRUCT(severity, root_cause_category, sample_error, downstream_impacted, last_updated_ts)
      ORDER BY
        CASE severity WHEN 'P0' THEN 1 WHEN 'P1' THEN 2 WHEN 'P2' THEN 3 ELSE 4 END,
        last_updated_ts DESC
      LIMIT 1
    )[OFFSET(0)] AS top
  FROM `vz-it-pr-hukv-cdwldo-0.ops_monitoring.ops_airflow_incident`
  WHERE status = 'OPEN'
  GROUP BY dag_id
),
base AS (
  SELECT
    dag_id,
    p95_duration_sec,
    avg_duration_sec,
    stddev_duration_sec,
    sample_count
  FROM `vz-it-pr-hukv-cdwldo-0.ops_monitoring.ops_airflow_baseline_metrics`
  WHERE window_days = 14
)
SELECT
  r.dag_id,

  -- Governance / routing
  r.airflow_tags,
  r.owner_emails,
  r.is_critical,
  r.sla_minutes,
  r.is_paused,
  r.is_egress,

  -- Latest run snapshot
  c.state AS last_state,
  c.last_seen,
  c.run_id AS last_run_id,
  c.duration_sec AS last_duration_sec,
  c.airflow_url,

  -- Incident (if any)
  i.top.severity AS open_incident_severity,
  i.top.root_cause_category AS open_incident_category,
  i.top.sample_error AS open_incident_summary,
  ARRAY_LENGTH(IFNULL(i.top.downstream_impacted, [])) AS downstream_impacted_count,

  -- Baseline
  b.sample_count AS baseline_samples_14d,
  b.p95_duration_sec AS baseline_p95_sec,

  -- Smart flags (what your Excel wants)
  CASE
    WHEN c.last_seen IS NULL THEN TRUE
    WHEN c.last_seen < TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 12 HOUR) THEN TRUE
    ELSE FALSE
  END AS is_stale_12h,

  CASE
    WHEN LOWER(IFNULL(c.state,'')) IN ('failed','up_for_retry') THEN TRUE
    WHEN i.top.severity IS NOT NULL THEN TRUE
    ELSE FALSE
  END AS has_issue,

  CASE
    WHEN c.duration_sec IS NULL OR b.p95_duration_sec IS NULL THEN FALSE
    WHEN c.duration_sec > (b.p95_duration_sec * 1.25) THEN TRUE
    ELSE FALSE
  END AS is_slow_vs_baseline,

  CASE
    WHEN r.sla_minutes IS NULL OR c.duration_sec IS NULL THEN FALSE
    WHEN c.duration_sec > (r.sla_minutes * 60) THEN TRUE
    ELSE FALSE
  END AS sla_breached
FROM reg r
LEFT JOIN cur c USING (dag_id)
LEFT JOIN inc i USING (dag_id)
LEFT JOIN base b USING (dag_id)
ORDER BY
  -- critical issues first
  CASE WHEN r.is_critical THEN 0 ELSE 1 END,
  CASE
    WHEN i.top.severity = 'P0' THEN 0
    WHEN i.top.severity = 'P1' THEN 1
    WHEN i.top.severity = 'P2' THEN 2
    WHEN i.top.severity IS NOT NULL THEN 3
    ELSE 4
  END,
  r.dag_id;
3) Optional: “Only failures today” report query
SELECT *
FROM (
  -- use the master query above as a subquery if you want
  -- OR just filter current_status + incident
  SELECT
    dag_id, state, last_seen, run_id, duration_sec, airflow_url
  FROM `vz-it-pr-hukv-cdwldo-0.ops_monitoring.ops_airflow_dag_current_status`
)
WHERE LOWER(state) IN ('failed', 'up_for_retry')
ORDER BY last_seen DESC;
Where to use these
Put MERGE (current_status) at the end of your 15-min monitoring DAG (after writing dag_run_fact).

Use the master consolidated query for:

hourly digest email table

dashboard

replacement for manual Excel sheet



If you want, I can also paste the exact Python code snippet to execute that MERGE from inside your 15-min DAG using BigQuery client (so it’s literally copy-paste).
